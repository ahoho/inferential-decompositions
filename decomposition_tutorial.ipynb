{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome! This notebook describes a method of generating inferential decompositions from text as introduced in our EMNLP 2023 paper: [Natural Language Decompositions of Implicit Content Enable Better Text Representations](https://arxiv.org/pdf/2305.14583.pdf)!\n",
    "\n",
    "We will guide you through the process step-by-step, and provide explanations and code snippets along the way. The method can be broken down into the following steps:\n",
    "\n",
    "1. **Sample a small number of items from your dataset**: Here, we use a dataset of tweets posted by legislators during the 115, 116 and 117th US Congresses. \n",
    "2. **Craft Implicit and Explicit Propositions**: Refer to Appendix 2. of our paper for a description of the instructions used in the paper to craft exemplar poropotitions. We will use the same instructions to craft implicit and explicit propositions for our dataset.\n",
    "3. **Prompt an LLM with the crafted exemplars**: Here, we will use GPT3.5 Turbo for our experiments. \n",
    "4. **Validate**: Confirm that a random sample of the generated decompositions are _plausible_.\n",
    "5. **Downstream Usage**: Use the decompositions in the target task. \n",
    "\n",
    "#### Getting Started\n",
    "\n",
    "To begin, run the first cell below to import the necessary packages and set up the environment. The helper functions and accompanying code are in `eval_mteb.py` and `generation_utils.py`. \n",
    "\n",
    "##### Note: \n",
    "We assume that your OPENAI_API_KEY is an environment variable. One way to set it is by running - `conda env config vars set OPENAI_API_KEY=<your_key_here>` inside your conda environment. It can also be set manually in the config by setting  `config[\"llm\"][\"openai_api_key\"]`.\n",
    "\n",
    "The code below was tested on a linux server, but should work on other hardware with alterations to pytorch versioning. \\[More additions coming soon!]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json \n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from simple_colors import * \n",
    "\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "from pathlib import Path\n",
    "\n",
    "from transformers import GenerationConfig \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing the data \n",
    "\n",
    "For the purpose of this tutorial, we choose a dataset of congressional tweets sampled from the 115th, 116th and 117th Congress. The data can be found in `data/sampled_tweets_senate_115-117.jsonl`.\n",
    "\n",
    "### Step 1: Sample a small number of items from your dataset\n",
    "\n",
    "In our case, we sample a small number of tweets from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc_utils import read_jsonl, write_jsonl, create_textboxes, show_document\n",
    "\n",
    "TWEETS_FILEPATH = Path('data/sampled_tweets_senate_115-117.jsonl')\n",
    "tweets = read_jsonl(TWEETS_FILEPATH)\n",
    "\n",
    "random.seed(42)\n",
    "exemplar_candidates = random.sample(tweets, 10)\n",
    "exemplar_tweets = [x['tweet'] for x in exemplar_candidates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64b605444fb44a8a60ad44660e2a1ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<h3 style='font-family: sans-serif; color:blue;'>Document 1:</h3><p style='font-family: Verdana'>G…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a6b86da12d4721b7863ec98b48bc8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<h3 style='font-family: sans-serif; color:blue;'>Document 2:</h3><p style='font-family: Verdana'>E…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84ee7413209498fb39618201240bc43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<h3 style='font-family: sans-serif; color:blue;'>Document 3:</h3><p style='font-family: Verdana'>O…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a1bfd50c9a64513b3ed44af7731fec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<h3 style='font-family: sans-serif; color:blue;'>Document 4:</h3><p style='font-family: Verdana'>F…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b747e7c0574b07b6690630031e158d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<h3 style='font-family: sans-serif; color:blue;'>Document 5:</h3><p style='font-family: Verdana'>T…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174598969c1146c4a0333e2019a6b513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<h3 style='font-family: sans-serif; color:blue;'>Document 6:</h3><p style='font-family: Verdana'>🚨…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8077bd26eca5406e9762295d844aae1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<h3 style='font-family: sans-serif; color:blue;'>Document 7:</h3><p style='font-family: Verdana'>@…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f04e3e51444db99c1b593385627c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<h3 style='font-family: sans-serif; color:blue;'>Document 8:</h3><p style='font-family: Verdana'>I…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc915810fb11475fac17478fe59223cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<h3 style='font-family: sans-serif; color:blue;'>Document 9:</h3><p style='font-family: Verdana'>S…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7370bec28c7f49cd931b64603f52b61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<h3 style='font-family: sans-serif; color:blue;'>Document 10:</h3><p style='font-family: Verdana'>…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See the sampled tweets\n",
    "\n",
    "for index, tweet in enumerate(exemplar_tweets): \n",
    "    text = show_document(index, tweet) \n",
    "    display(text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Craft Implicit and Explicit Propositions\n",
    "In this step, we craft both explicit and implicit exemplars for the sampled tweets. Fill up the textboxes next to the tweets with propositons and press the \"Submit\" button when you're done. \n",
    "\n",
    "##### TIP: \n",
    "If you want to start with the exemplars used in the paper, turn the ```start_with_existing_exemplars``` flag to ```True``` in the next cell.\n",
    "\n",
    "Our sampled tweets and exemplars can also be found in  `exemplars/leg_tweets_exemplars.jsonl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_with_existing_exemplars = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4afb63a3644d428abb5bba2a140dea6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<h3 style='font-family: sans-serif; color:blue;'>Document 1:</h3><p style='font-family: Verdana'>T…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012827accb7b4ceea38d6598575b9e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='The Honest Ads Act will strengthen protections against foreign election interference\\nRussia w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c2f2398a25498a9ba7596324e8f434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fff959990ef4d3d94100300118c81e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<h3 style='font-family: sans-serif; color:blue;'>Document 2:</h3><p style='font-family: Verdana'>O…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d7937ceaf54f18940846a7225a1b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value=\"A police officer killed George Floyd\\nGeorge Floyd's death was unjust\\nBlack Americans deserve…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74402645f4d8442dbba01c246cc71553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee7491069f6646fa90a43654e8b46da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<h3 style='font-family: sans-serif; color:blue;'>Document 3:</h3><p style='font-family: Verdana'>H…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f4f3bff8415460ea6cd8d1c79230f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value=\"Wyoming was the fist state to recognize womens' right to vote\\nWyoming supports gender equalit…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748679b845584fa1bd43dac5c3878202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56dad5173294e38915d30e259ccd5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3 style=\\'font-family: sans-serif; color:blue;\\'>Document 4:</h3><p style=\\'font-family: Verdana…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee775f9afab44008fcfd2b113737d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value=\"Mark Zuckerberg makes insincere apologies\\nFacebook is trying to avoid accountability\\nFaceboo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad1d2a4708840f0bb33a953091efcb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c51b32d6629c47c9aae60ffb6f4927cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<h3 style='font-family: sans-serif; color:blue;'>Document 5:</h3><p style='font-family: Verdana'>F…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29b606a413c4b8a89ac589a252eb8bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='There is an urgent need to help DACA recipients\\nSupport for Dreamers is bipartisan\\nDACA rece…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65101d6b21be4e74a4e78025973212ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweet_decomp_exemplars = []\n",
    "\n",
    "if not start_with_existing_exemplars : \n",
    "    random.seed(42)\n",
    "    exemplar_candidates = random.sample(tweets, 10)\n",
    "    exemplar_tweets = [x['tweet'] for x in exemplar_candidates]\n",
    "\n",
    "else: \n",
    "    # load exemplars used in the paper \n",
    "    paper_exemplars = read_jsonl(\"exemplars/leg_tweets_exemplars.jsonl\")\n",
    "    exemplar_tweets = [x[0] for x in paper_exemplars] \n",
    "    exemplar_decomps = [x[1] for x in paper_exemplars] \n",
    "\n",
    "for index, tweet in enumerate(exemplar_tweets[:5]): # remove slicing to include all tweets\n",
    "    fancy_text = show_document(index, tweet)\n",
    "    \n",
    "    # display the document \n",
    "    display(fancy_text)\n",
    "    \n",
    "    if start_with_existing_exemplars: \n",
    "        decomps = create_textboxes(\"\\n\".join(exemplar_decomps[index]))\n",
    "    else: \n",
    "        decomps = create_textboxes()\n",
    "    \n",
    "    tweet_decomp_exemplars.append([tweet, decomps])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Save them in the right format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"exemplars/user_collected_exemplars.jsonl\", \"w\") as f: \n",
    "    for elem in tweet_decomp_exemplars: \n",
    "        s= json.dumps(elem)\n",
    "        f.write(f\"{s}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Prompting a LLM with the crafted exemplars\n",
    "\n",
    "We use the `GenerationEmbedder` class from `eval_mteb.py` along with the hyperparameters specified in `configs/leg-tweet-gen-gpt3.5-propositions-all.yaml` to prompt GPT3.5 Turbo with the exemplars. The generated decompositions can be found in `data/gpt3.5_tweets_to_gen_all.jsonl`. \n",
    "\n",
    "Similar to **Step 2**, if you want to use the exemplars described in our paper, set `use_existing_exemplars = True` in the next cell. If you altered and submitted your own decompositionsin the previous cell, set `use_existing_exemplars=False`. \n",
    "\n",
    "**NOTE**: If you didn't submit anything in the last interactive shell, set `use_existing_exemplars` to `False`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_existing_exemplars = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fs/clip-political/rupak/miniconda3/envs/decompositions/lib/python3.10/site-packages/langchain/llms/openai.py:716: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from eval_mteb import  GenerationEmbedder, load_config\n",
    "\n",
    "TWEETS_FILEPATH = Path('data/sampled_tweets_senate_115-117.jsonl')\n",
    "tweets = read_jsonl(TWEETS_FILEPATH)\n",
    "\n",
    "# load the config file and the exemplars \n",
    "config = load_config('configs/leg-tweet-gen-gpt3.5-propositions-all.yaml')\n",
    "\n",
    "# use existing exemplars or \n",
    "if use_existing_exemplars is True: \n",
    "    exemplars = read_jsonl(config[\"data\"]['exemplars_path'])\n",
    "else: \n",
    "    exemplars = read_jsonl(\"exemplars/user_collected_exemplars.jsonl\") \n",
    "\n",
    "# initialize the generation object with hyperparameters loaded from the config file\n",
    "model = GenerationEmbedder(\n",
    "    instructions=config[\"data\"][\"instructions\"],\n",
    "    openai_api_key=config[\"llm\"][\"openai_api_key\"],\n",
    "    exemplar_pool=exemplars,\n",
    "    exemplar_format=config[\"exemplars\"][\"format\"],\n",
    "    exemplar_sep=config[\"exemplars\"][\"separator\"],\n",
    "    multi_output_sep=config[\"exemplars\"][\"multi_output_separator\"],\n",
    "    exemplars_per_prompt=config[\"exemplars\"][\"exemplars_per_prompt\"],\n",
    "    draws_per_pool=config[\"exemplars\"][\"draws_per_pool\"],\n",
    "    repeat_draws=config[\"exemplars\"][\"repeat_draws\"],\n",
    "    shuffles_per_draw=config[\"exemplars\"][\"shuffles_per_draw\"],\n",
    "    output_combination_strategy=config[\"embeddings\"][\"output_combination_strategy\"],\n",
    "    include_original_doc=config[\"embeddings\"][\"include_original_doc\"],\n",
    "    embedding_model_name=config[\"embeddings\"][\"embedding_model_name\"],\n",
    "    gen_model_name=config[\"llm\"][\"gen_model_name\"],\n",
    "    generations_per_prompt=config[\"llm\"][\"generations_per_prompt\"],\n",
    "    temperature=config[\"llm\"][\"temperature\"],\n",
    "    top_p=config[\"llm\"][\"top_p\"],\n",
    "    generation_kwargs=config[\"llm\"][\"generation_kwargs\"],\n",
    "    max_tokens=config[\"llm\"][\"max_tokens\"],\n",
    "    cache_db_path=config[\"main\"][\"cache_db_path\"],\n",
    "    dry_run=config[\"main\"][\"dry_run\"],\n",
    "    device=config[\"embeddings\"][\"device\"],\n",
    "    seed=config[\"main\"][\"seed\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of the tutorial, we are generating decompositions for the first 20 tweets which is stored in `outputs/test_outputs.jsonl`. Decompositions for the entire dataset can be found in `data/gpt3.5_tweets_to_gen_all.jsonl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate propositions from tweets \n",
    "# simple batching code that deals with breaks in connections\n",
    "\n",
    "# use a small sample of tweets to test the generations\n",
    "\n",
    "OUTPUT_PATH = Path(\"outputs/test_outputs.jsonl\") \n",
    "\n",
    "# create a fresh file each time for testing outputs \n",
    "with OUTPUT_PATH.open(mode='w'): \n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                   | 0/2 [00:00<?, ?it/s]\n",
      "  0%|                                                                                                                                                                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|████████████████████▏                                                                                                                                                                                     | 1/10 [00:01<00:13,  1.52s/it]\u001b[A\n",
      " 20%|████████████████████████████████████████▍                                                                                                                                                                 | 2/10 [00:02<00:09,  1.13s/it]\u001b[A\n",
      " 30%|████████████████████████████████████████████████████████████▌                                                                                                                                             | 3/10 [00:03<00:07,  1.06s/it]\u001b[A\n",
      " 40%|████████████████████████████████████████████████████████████████████████████████▊                                                                                                                         | 4/10 [00:04<00:05,  1.05it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                     | 5/10 [00:05<00:05,  1.14s/it]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                | 6/10 [00:07<00:04,  1.25s/it]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                            | 7/10 [00:08<00:04,  1.34s/it]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                        | 8/10 [00:09<00:02,  1.34s/it]\u001b[A\n",
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                    | 9/10 [00:11<00:01,  1.30s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:12<00:00,  1.21s/it]\u001b[A\n",
      "WARNING:root:Truncated 0 out of 10 prompts\n",
      " 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                     | 1/2 [00:12<00:12, 12.15s/it]\n",
      "  0%|                                                                                                                                                                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|████████████████████▏                                                                                                                                                                                     | 1/10 [00:01<00:15,  1.70s/it]\u001b[A\n",
      " 20%|████████████████████████████████████████▍                                                                                                                                                                 | 2/10 [00:02<00:09,  1.22s/it]\u001b[A\n",
      " 30%|████████████████████████████████████████████████████████████▌                                                                                                                                             | 3/10 [00:03<00:07,  1.12s/it]\u001b[A\n",
      " 40%|████████████████████████████████████████████████████████████████████████████████▊                                                                                                                         | 4/10 [00:04<00:06,  1.06s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                     | 5/10 [00:05<00:05,  1.10s/it]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                | 6/10 [00:07<00:05,  1.35s/it]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                            | 7/10 [00:08<00:04,  1.34s/it]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                        | 8/10 [00:10<00:02,  1.42s/it]\u001b[A\n",
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                    | 9/10 [00:11<00:01,  1.30s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:12<00:00,  1.26s/it]\u001b[A\n",
      "WARNING:root:Truncated 0 out of 10 prompts\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:24<00:00, 12.38s/it]\n"
     ]
    }
   ],
   "source": [
    "if not OUTPUT_PATH.is_file():\n",
    "    # If it doesn't exist, create the file\n",
    "    OUTPUT_PATH.touch()\n",
    "\n",
    "tweet_texts = [tweet['tweet'] for tweet in tweets][:20] # remove [:20] to run on all tweets\n",
    "propositions = read_jsonl(OUTPUT_PATH)\n",
    "\n",
    "batch_size = 10\n",
    "for index in tqdm(range(len(propositions), len(tweet_texts), batch_size)):\n",
    "    batch = tweet_texts[index:index+batch_size]\n",
    "    propositions.extend(model.generate_from_inputs(batch))\n",
    "    write_jsonl(propositions, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Validate\n",
    "\n",
    "We sample some of the generated decompositions and confirm that they are _plausible_. In our paper, this was done using a human study. Please refer to Section 3 of our paper for more details. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TWEET: \n",
      "\u001b[34mIgnoring #climatechange won't prevent devastating storms. People's lives depend on all of us acknowledging that #ClimateChangeIsReal  \u001b[0m\n",
      "\n",
      "PROPOSITONS:\n",
      "\u001b[32mIgnoring climate change won't prevent devastating storms\u001b[0m\n",
      "\u001b[32mClimate change is a real and urgent issue\u001b[0m\n",
      "\u001b[32mPeople's lives are at risk due to climate change\u001b[0m\n",
      "\u001b[32mWe need to acknowledge and address climate change\u001b[0m\n",
      "\n",
      "---------------------------\n",
      "\n",
      "TWEET: \n",
      "\u001b[34mWe must do more to address mental health issues our veterans face and ensure all have access to treatment. @WSAZnews #suicidepreventionmonth  \u001b[0m\n",
      "\n",
      "PROPOSITONS:\n",
      "\u001b[32mVeterans face mental health issues\u001b[0m\n",
      "\u001b[32mAccess to mental health treatment for veterans is insufficient\u001b[0m\n",
      "\u001b[32mMore needs to be done to address mental health issues among veterans\u001b[0m\n",
      "\u001b[32mSuicide prevention is important for veterans\u001b[0m\n",
      "\u001b[32mMental health support for veterans is lacking\u001b[0m\n",
      "\n",
      "---------------------------\n",
      "\n",
      "TWEET: \n",
      "\u001b[34mElizabeth Cady Stanton. Lucretia Mott. Susan B. Anthony.\n",
      " \n",
      "These strong women were true pioneers in the fight for women’s rights, &amp; they continue to inspire me today. I visited a reminder of their incredible contributions in the @uscapitol earlier this week.  #WomensHistoryMonth  \u001b[0m\n",
      "\n",
      "PROPOSITONS:\n",
      "\u001b[32mElizabeth Cady Stanton was a pioneer in the women's rights movement\u001b[0m\n",
      "\u001b[32mLucretia Mott fought for women's rights\u001b[0m\n",
      "\u001b[32mSusan B. Anthony made significant contributions to women's rights\u001b[0m\n",
      "\u001b[32mWomen's rights activists should be celebrated\u001b[0m\n",
      "\u001b[32mThe US Capitol commemorates the achievements of women's rights activists\u001b[0m\n",
      "\n",
      "---------------------------\n",
      "\n",
      "TWEET: \n",
      "\u001b[34mThe cultural &amp; natural history of the @NewRiverNPS expands over 70,000 acres in WV. But we don’t currently have the funds necessary to maintain this beautiful WV landmark. I introduced a bill this wk to address the maintenance backlog at our national parks    \u001b[0m\n",
      "\n",
      "PROPOSITONS:\n",
      "\u001b[32mThe New River National Park has a rich cultural and natural history\u001b[0m\n",
      "\u001b[32mThe park spans over 70,000 acres in West Virginia\u001b[0m\n",
      "\u001b[32mFunding is needed to maintain the New River National Park\u001b[0m\n",
      "\u001b[32mA bill has been introduced to address the maintenance backlog at national parks\u001b[0m\n",
      "\u001b[32mNational parks play an important role in preserving natural landmarks\u001b[0m\n",
      "\n",
      "---------------------------\n",
      "\n",
      "TWEET: \n",
      "\u001b[34mHappy #Juneteenth, a day commemorating freedom for thousands of enslaved African Americans in Texas two years after the Emancipation Proclamation. Today, we celebrate freedom and recommit ourselves to equality, justice and opportunity for all Americans.\u001b[0m\n",
      "\n",
      "PROPOSITONS:\n",
      "\u001b[32mJuneteenth commemorates the freedom of enslaved African Americans\u001b[0m\n",
      "\u001b[32mJuneteenth signifies progress towards equality and justice\u001b[0m\n",
      "\u001b[32mEmancipation Proclamation led to the freedom of enslaved individuals\u001b[0m\n",
      "\u001b[32mCommitment to equality, justice, and opportunity for all Americans\u001b[0m\n",
      "\u001b[32mJuneteenth represents the ongoing fight for civil rights\u001b[0m\n",
      "\n",
      "---------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# before sampling, make sure to keep the tweet with the generations: \n",
    "\n",
    "for tweet_text, props in zip(tweet_texts, propositions):\n",
    "    props.append(tweet_text)\n",
    "\n",
    "# sample from the propositions\n",
    "random.seed(42)\n",
    "sample = random.sample(propositions, 5)\n",
    "\n",
    "for elem in sample: \n",
    "    print(f\"TWEET: \\n{blue(elem[-1])}\\n\")\n",
    "    print(\"PROPOSITONS:\")\n",
    "    for prop in elem[:-1]:\n",
    "        print(green(prop))\n",
    "    print(\"\\n---------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Use the propositions for your own downstream task!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding tweets with implicit similarity\n",
    "\n",
    "When we embed a document through the surface form of its content, documents with a similar communicative intent but are expressed differently in their lexical forms are placed further in the embedding space. \n",
    "\n",
    "To find such document pairs, we can make use of the inferential decompositions we obtained above. These decompositions helps us get over the lexical choices of a communicator, and lets us focus instead on their communicative intent. Hence, documents that seem far in the embedding space are brought closer through their similar decompositions. \n",
    "\n",
    "Here, we show some samples of such document pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc_utils import distance_func\n",
    "# NOTE: distance_func is a simple distance function that returns the minimum pairwise distance among all possible inferences of a pair of tweets. \n",
    "\n",
    "# tweets\n",
    "tweet_texts = [x['tweet'] for x in tweets] \n",
    "\n",
    "# load all the decompositions \n",
    "decompositions = read_jsonl(\"data/gpt3.5_tweets_to_gen_all.jsonl\") \n",
    "\n",
    "assert len(tweet_texts) == len(decompositions), \"Length of documents don't match length of decompositions\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca2a60ffec464fc09b64b80972cb7959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8728d911da2a42688da5179b5aa2437e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf426dcfefe489182efdd5193ccc84b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10238e5e90cf4ea7a6abbefa2d794d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b067d7a5b7ad4ce3bea344eb146e0564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "054f9f05026148c9bba1a71d6dc21b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb71f93de78429bbbf92e6461bd396c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35d1939820c46f2afb2284f18534646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97661c1db3df4555a923812d19159dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b657b6f70cc941489b514c93e4013d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1adcb94d1db1407aa37fdfb1df033dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828d2b71af33466fa30c21dd875e3199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39284/39284 [05:01<00:00, 130.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "st_model = SentenceTransformer(\"all-MiniLM-L6-v2\") \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# compute embeddings and embedding similarities \n",
    "doc_embeddings = st_model.encode(tweet_texts, device=device, show_progress_bar=True) \n",
    "doc_distances = 1 - cos_sim(doc_embeddings, doc_embeddings) \n",
    "\n",
    "# compute embeddings of decompositions\n",
    "# depending on your dataset, this might take a little bit of time\n",
    "decomp_embeddings = np.array([st_model.encode(x, device=device) for x in tqdm(decompositions)], dtype=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 499500/499500 [01:52<00:00, 4426.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# create a matrix of decomposition distances \n",
    "# try with only a subset of comments for speed \n",
    "doc_sample_size = 1000\n",
    "\n",
    "from itertools import combinations \n",
    "pairs = list(combinations(range(doc_sample_size), 2)) \n",
    "\n",
    "decomp_dists = np.zeros((doc_sample_size, doc_sample_size)) \n",
    "\n",
    "for pair in tqdm(pairs): \n",
    "    index1, index2 = pair\n",
    "    decomp_dists[index1, index2] = distance_func(decomp_embeddings[index1], decomp_embeddings[index2])[2]\n",
    "    decomp_dists[index2, index1] = decomp_dists[index1, index2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding tweet pairs that move closer in decomposition embedding space\n",
    "\n",
    "In the next cell, we try to find pairs of documents (here, tweets) that move closer in embedding space once we look at their decompositions. The shift in distance is a hyperparameter, and best results can be obtained by setting a value that is meaningful for your dataset. \n",
    "\n",
    "Since we are using a distance function that looks at the minimum distance between all possible decompositions, the decomposition that brings the tweets closer is highlighted in <font color='red'>red</font>. The <font color='blue'>tweets</font> are colored in <font color='blue'>blue</font>, and <font color='green'>decompositions</font> in <font color='green'>green</font>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|██▊                                                                                                                                                                                              | 7437/499500 [00:02<03:20, 2455.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 20\n",
      "Distance moved from 0.680652379989624 -> 0.1971825361251831\n",
      "\u001b[34mThe cultural &amp; natural history of the @NewRiverNPS expands over 70,000 acres in WV. But we don’t currently have the funds necessary to maintain this beautiful WV landmark. I introduced a bill this wk to address the maintenance backlog at our national parks    \u001b[0m\n",
      "\u001b[32m['New River National Park is an important part of cultural and natural history', 'The park requires funds to properly maintain it', \"The park is an important part of West Virginia's heritage\", 'Legislation has been introduced to address park maintenance', 'National Parks are an important part of American heritage']\u001b[0m\n",
      "\u001b[31mNational Parks are an important part of American heritage\u001b[0m\n",
      "\u001b[34mOur #MonumentsForAll belong to all of us. They should not be sold off to the highest bidder. We will keep fighting to protect these special places which are a part of our history, our heritage, our local economies and our way of life.\u001b[0m\n",
      "\u001b[32m['National monuments are important for American heritage', 'They should be protected from profiteering', 'National monuments support local economies', 'Special places deserve protection', 'National monuments belong to all Americans']\u001b[0m\n",
      "\u001b[31mNational monuments are important for American heritage\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|████▏                                                                                                                                                                                           | 11019/499500 [00:03<03:11, 2550.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 819\n",
      "Distance moved from 0.5271098613739014 -> 0.11885702610015869\n",
      "\u001b[34mThousands in DC will #MarchforLife today, the 45th anniversary of Roe v. Wade. As they march, they speak with one voice: \"Life is sacred. Life is precious. Life is worth protecting.\" I stand with them &amp; all #ProLife Americans in defense of the unborn. #WhyWeMarch @March_for_Life\u001b[0m\n",
      "\u001b[32m['Marchers believe that human life is sacred and valuable', 'Abortion should be illegal', 'The pro-life position is important', 'The March for Life is significant', 'Americans have a right to protest peacefully']\u001b[0m\n",
      "\u001b[31mThe March for Life is significant\u001b[0m\n",
      "\u001b[34mI stand with students across #NM and America who are marching against gun violence, and look forward to joining the #MarchForOurLives in Santa Fe today. I pledge to do everything I can to enact common sense gun safety measures and end the gun lobby’s stranglehold over Washington.  \u001b[0m\n",
      "\u001b[32m['Students are protesting gun violence across America', 'The March For Our Lives is an important event', 'Gun safety measures should be put into place', 'The gun lobby has too much influence over US politics', 'Gun violence needs to be addressed']\u001b[0m\n",
      "\u001b[31mThe March For Our Lives is an important event\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█████▍                                                                                                                                                                                          | 14242/499500 [00:04<02:54, 2778.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 934\n",
      "Distance moved from 0.6534669399261475 -> 0.1397610306739807\n",
      "\u001b[34mHere we go again. We need an EPA administrator who will protect our air, water and soil, not someone who’s made a career by making it easier for corporations to trash our environment. \u001b[0m\n",
      "\u001b[32m['The new EPA Administrator should prioritize protecting the environment', 'Previous Administrators have been complicit in allowing corporations to pollute', 'The environment is in need of protection', 'Protecting the environment is a serious responsibility of the EPA.']\u001b[0m\n",
      "\u001b[31mThe environment is in need of protection\u001b[0m\n",
      "\u001b[34m.@kabbottBHN, president of @BostonHarborNow, highlighted the importance of tourism and recreation to New England's coastal economy. Our coastal communities cannot afford an oil spill.\n",
      "\n",
      "#ProtectOurCoast\u001b[0m\n",
      "\u001b[32m[\"Tourism is important to New England's coastal economy\", 'Protecting the coast from oil spills is essential', 'Coastal economies are vulnerable to oil spills', 'Coastal tourism would suffer from an oil spill', 'The environment should be protected']\u001b[0m\n",
      "\u001b[31mThe environment should be protected\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█████▊                                                                                                                                                                                          | 15048/499500 [00:05<03:12, 2517.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 691\n",
      "Distance moved from 0.6972323656082153 -> 0.26385557651519775\n",
      "\u001b[34mOur tax laws should encourage US companies to keep #jobs here, not send them abroad. The new tax law actually created an incentive to move jobs abroad to take advantage of tax havens. Sen Klobuchar introduced a bill to close that loophole &amp; protect US jobs \u001b[0m\n",
      "\u001b[32m['Tax laws should incentivize companies to keep jobs in the US', 'The new tax law created an incentive for outsourcing', 'Tax havens should not be used to avoid US taxes', 'Senator Klobuchar introduced a bill to prevent outsourcing and tax avoidance', 'American jobs need to be protected']\u001b[0m\n",
      "\u001b[31mAmerican jobs need to be protected\u001b[0m\n",
      "\u001b[34mExactly right. The Finger Lakes region is not and will never be a good location for this incinerator, and we have to stand strong to protect local jobs, so many in the tourism industry, &amp; our precious natural resources. #FLX \u001b[0m\n",
      "\u001b[32m['The Finger Lakes region is a poor choice for the incinerator', 'Protection of jobs is important', 'The tourism industry is important to the region', 'Natural resources need protection', 'The incinerator will harm the natural environment.']\u001b[0m\n",
      "\u001b[31mProtection of jobs is important\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████████▉                                                                                                                                                                                       | 23409/499500 [00:08<02:53, 2742.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 55\n",
      "Distance moved from 0.7091791033744812 -> 0.2626243829727173\n",
      "\u001b[34mDirector Pompeo’s recent trip to North Korea, I believe, highlights how effective and committed he is to pursuing diplomatic opportunities.\u001b[0m\n",
      "\u001b[32m['Mike Pompeo is committed to diplomacy', 'Pompeo recently visited North Korea', 'Diplomacy is the preferred strategy for conflict resolution', 'Pompeo is an effective leader']\u001b[0m\n",
      "\u001b[31mDiplomacy is the preferred strategy for conflict resolution\u001b[0m\n",
      "\u001b[34mPleased to be joined by RI's Honorary Consul of France, Roger Begin, for French President @EmmanuelMacron’s address to a joint session of Congress. \u001b[0m\n",
      "\u001b[32m[\"Rhode Island Honorary Consul Roger Begin joined in for President Macron's address to Congress\", 'The French President addressed both houses of Congress', 'The United States has friendly diplomatic relations with France', 'Diplomacy is important for international relations']\u001b[0m\n",
      "\u001b[31mDiplomacy is important for international relations\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n",
      "23 429\n",
      "Distance moved from 0.7630152702331543 -> 0.28250575065612793\n",
      "\u001b[34mDirector Pompeo’s recent trip to North Korea, I believe, highlights how effective and committed he is to pursuing diplomatic opportunities.\u001b[0m\n",
      "\u001b[32m['Mike Pompeo is committed to diplomacy', 'Pompeo recently visited North Korea', 'Diplomacy is the preferred strategy for conflict resolution', 'Pompeo is an effective leader']\u001b[0m\n",
      "\u001b[31mDiplomacy is the preferred strategy for conflict resolution\u001b[0m\n",
      "\u001b[34mPulling out of the Iran deal would make us less safe. My statement on the President's remarks on Iran: \u001b[0m\n",
      "\u001b[32m['Pulling out of the Iran deal makes the US less secure', \"President's position on Iran is dangerous\", 'Diplomacy with Iran is the best way to ensure peace', 'International cooperation should be prioritized', 'Disagreements with Iran should be resolved peacefully']\u001b[0m\n",
      "\u001b[31mDiplomacy with Iran is the best way to ensure peace\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████████▎                                                                                                                                                                                      | 24119/499500 [00:08<02:29, 3170.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 729\n",
      "Distance moved from 0.47134125232696533 -> 0.05430161952972412\n",
      "\u001b[34mDirector Pompeo’s recent trip to North Korea, I believe, highlights how effective and committed he is to pursuing diplomatic opportunities.\u001b[0m\n",
      "\u001b[32m['Mike Pompeo is committed to diplomacy', 'Pompeo recently visited North Korea', 'Diplomacy is the preferred strategy for conflict resolution', 'Pompeo is an effective leader']\u001b[0m\n",
      "\u001b[31mDiplomacy is the preferred strategy for conflict resolution\u001b[0m\n",
      "\u001b[34mI'm heartened to see the progress between South Korea and North Korea today. Dialogue and robust diplomacy are key, as I wrote for @CNN in January. I hope it continues.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m['The diplomatic situation between South Korea and North Korea is improving', 'Dialogue is necessary for peace', 'Diplomacy is key for conflict resolution', 'Military action is not always the answer']\u001b[0m\n",
      "\u001b[31mDiplomacy is key for conflict resolution\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n",
      "24 254\n",
      "Distance moved from 0.6566081047058105 -> 0.24104851484298706\n",
      "\u001b[34mWe are not going to ABANDON the wall.\n",
      "\n",
      "We are going to BUILD the wall!\u001b[0m\n",
      "\u001b[32m['The wall will be built', 'The wall is a priority', 'There is an opposition to the wall', 'Construction of the wall is necessary', 'Abandoning the wall is not an option']\u001b[0m\n",
      "\u001b[31mThe wall is a priority\u001b[0m\n",
      "\u001b[34mJoin me Thursday at Heritage for keynote address on my bill to force sanctuary cities to #followthelaworfundthewall\n",
      "\u001b[0m\n",
      "\u001b[32m['Join me at Heritage on Thursday for my keynote address', 'My bill aims to enforce the law on sanctuary cities', 'My bill suggests taking funding from sanctuary cities to fund the wall', 'Immigration policy is a key issue for my constituents', 'Supporting the border wall is a priority']\u001b[0m\n",
      "\u001b[31mSupporting the border wall is a priority\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|███████████▉                                                                                                                                                                                    | 31215/499500 [00:10<02:25, 3213.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 177\n",
      "Distance moved from 0.733190655708313 -> 0.2248525619506836\n",
      "\u001b[34mYesterday in Senate Finance, I spoke out about the outrageous policy of separating children from their parents at the border.  \u001b[0m\n",
      "\u001b[32m['Children should not be separated from their parents at the border', 'Separating families is cruel and unusual', 'The US immigration system needs fixing', 'Human rights are important and should be respected', \"The Trump administration's immigration policies are immoral\"]\u001b[0m\n",
      "\u001b[31mThe US immigration system needs fixing\u001b[0m\n",
      "\u001b[34mFixing our immigration system is important, but #RAISE Act would be harmful to our nation’s values &amp; economy. Full statement: \u001b[0m\n",
      "\u001b[32m['Our immigration system needs to be reformed', 'RAISE Act is not the solution', 'RAISE Act would harm American economy', 'RAISE Act would be detrimental to American values', 'Immigration is a key component of American prosperity']\u001b[0m\n",
      "\u001b[31mOur immigration system needs to be reformed\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n",
      "31 202\n",
      "Distance moved from 0.7122502326965332 -> 0.17709392309188843\n",
      "\u001b[34mYesterday in Senate Finance, I spoke out about the outrageous policy of separating children from their parents at the border.  \u001b[0m\n",
      "\u001b[32m['Children should not be separated from their parents at the border', 'Separating families is cruel and unusual', 'The US immigration system needs fixing', 'Human rights are important and should be respected', \"The Trump administration's immigration policies are immoral\"]\u001b[0m\n",
      "\u001b[31mThe US immigration system needs fixing\u001b[0m\n",
      "\u001b[34mRescinding #DACA doesn't fix our broken immigration system. It bullies vulnerable, hardworking immigrants &amp; their families. #ProtectDREAMers\u001b[0m\n",
      "\u001b[32m['Revoking DACA is not a solution to immigration problems', 'Immigrants deserve dignity', 'Dreamers should be protected', 'Hardworking immigrants should be valued', 'Immigration policy needs fixing']\u001b[0m\n",
      "\u001b[31mImmigration policy needs fixing\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████████████▎                                                                                                                                                                                   | 31919/499500 [00:11<02:18, 3380.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 997\n",
      "Distance moved from 0.877120316028595 -> 0.28157633543014526\n",
      "\u001b[34mYesterday in Senate Finance, I spoke out about the outrageous policy of separating children from their parents at the border.  \u001b[0m\n",
      "\u001b[32m['Children should not be separated from their parents at the border', 'Separating families is cruel and unusual', 'The US immigration system needs fixing', 'Human rights are important and should be respected', \"The Trump administration's immigration policies are immoral\"]\u001b[0m\n",
      "\u001b[31mThe US immigration system needs fixing\u001b[0m\n",
      "\u001b[34mThe RAISE Act would raise working Americans’ wages by giving priority to the best-skilled immigrants.  \u001b[0m\n",
      "\u001b[32m['The RAISE Act would prioritize highly skilled immigrants', 'Skilled immigrants are more likely to raise wages for American workers', 'Prioritizing high-skill immigration could improve the US economy', 'The US government should reform its immigration policy']\u001b[0m\n",
      "\u001b[31mThe US government should reform its immigration policy\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n",
      "32 732\n",
      "Distance moved from 0.5486396551132202 -> 0.0396428108215332\n",
      "\u001b[34mMore good news for American workers. More good news for our economy. More proof that #ThisGOPAgendaWorks  \u001b[0m\n",
      "\u001b[32m['The GOP agenda works', 'The American economy is improving', 'American workers are benefiting from the GOP agenda', 'Americans should support the GOP agenda']\u001b[0m\n",
      "\u001b[31mThe American economy is improving\u001b[0m\n",
      "\u001b[34mWith 233,000 jobs added in May, the unemployment rate has reached its lowest level since 2000!\n",
      " \n",
      "\u001b[0m\n",
      "\u001b[32m['The May jobs report shows the unemployment rate is at its lowest since 2000', 'The US economy is improving', 'Job creation is important', 'The labor market is growing']\u001b[0m\n",
      "\u001b[31mThe US economy is improving\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|████████████▌                                                                                                                                                                                   | 32611/499500 [00:11<02:23, 3245.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 815\n",
      "Distance moved from 0.6179099082946777 -> 0.12021374702453613\n",
      "\u001b[34mMore good news for American workers. More good news for our economy. More proof that #ThisGOPAgendaWorks  \u001b[0m\n",
      "\u001b[32m['The GOP agenda works', 'The American economy is improving', 'American workers are benefiting from the GOP agenda', 'Americans should support the GOP agenda']\u001b[0m\n",
      "\u001b[31mThe American economy is improving\u001b[0m\n",
      "\u001b[34mFewer Americans are filing for unemployment today than at any time since 1969, a 48 year low.  \u001b[0m\n",
      "\u001b[32m['The number of Americans filing for unemployment is at a 48 year low', 'Fewer Americans are unemployed than in previous years', 'The economy is improving', 'The job market is better than it has been in decades']\u001b[0m\n",
      "\u001b[31mThe economy is improving\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████████████▉                                                                                                                                                                                  | 36127/499500 [00:12<02:13, 3482.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 120\n",
      "Distance moved from 0.6662979125976562 -> 0.21766602993011475\n",
      "\u001b[34mLife begins at conception! I proudly stand with the Pro-Life movement and #StandForLife! \u001b[0m\n",
      "\u001b[32m['Life begins at conception', 'The pro-life movement is important to support', 'Abortion should be illegal', 'Unborn children have a right to life', 'Human life is valuable at all stages of development']\u001b[0m\n",
      "\u001b[31mAbortion should be illegal\u001b[0m\n",
      "\u001b[34mOverturning #RoevWade would not end abortion, it would just end safe abortion.\u001b[0m\n",
      "\u001b[32m['Reversing Roe v. Wade would not put an end to abortion', 'Women would still seek abortions', 'Abortions should be safe', 'Overturning Roe v. Wade would threaten safe abortions', \"Roe v. Wade protects a woman's right to abortion\"]\u001b[0m\n",
      "\u001b[31mAbortions should be safe\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n",
      "36 459\n",
      "Distance moved from 0.6714107394218445 -> 0.2247447967529297\n",
      "\u001b[34mLife begins at conception! I proudly stand with the Pro-Life movement and #StandForLife! \u001b[0m\n",
      "\u001b[32m['Life begins at conception', 'The pro-life movement is important to support', 'Abortion should be illegal', 'Unborn children have a right to life', 'Human life is valuable at all stages of development']\u001b[0m\n",
      "\u001b[31mThe pro-life movement is important to support\u001b[0m\n",
      "\u001b[34mFederal dollars should never be used to perform abortions. It’s our obligation to defend and protect life. \u001b[0m\n",
      "\u001b[32m['Federal funding should not be used to fund abortions', 'Abortion is not an acceptable use of taxpayer money', 'Life should be valued and protected', 'The government should support pro-life policies']\u001b[0m\n",
      "\u001b[31mThe government should support pro-life policies\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████████████▉                                                                                                                                                                                 | 38813/499500 [00:13<02:43, 2810.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 164\n",
      "Distance moved from 0.6268095970153809 -> 0.07287865877151489\n",
      "\u001b[34mOn the anniversary of the horrific shooting at Columbine, students are again walking out of their classrooms to call for an end to senseless gun violence. These young people are right -- #enough. We need to enact common-sense gun safety legislation now.  \u001b[0m\n",
      "\u001b[32m['Students are walking out of classrooms to protest gun violence', 'Gun violence is a serious problem in America', 'Gun control is a necessary step to end violence', 'America needs common-sense gun safety legislation', 'Columbine was a tragic event that should not be forgotten']\u001b[0m\n",
      "\u001b[31mGun violence is a serious problem in America\u001b[0m\n",
      "\u001b[34mAt 2:33 PM, it will be one week since five members of the @capgaznews family were killed in a horrific act of gun violence.\n",
      "\n",
      "At 2:33 PM, I'll be participating in a moment of silence – in honor of their lives, their memories and their families. Join me.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m['The Capital Gazette shooting was a horrific act of gun violence', 'A moment of silence should be observed to honor the victims', 'The families of the victims deserve support', 'Gun violence is a problem in the United States', 'Journalists play an important role in society']\u001b[0m\n",
      "\u001b[31mGun violence is a problem in the United States\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|█████████████████▏                                                                                                                                                                              | 44761/499500 [00:15<02:13, 3395.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 445\n",
      "Distance moved from 0.7276068925857544 -> 0.16445177793502808\n",
      "\u001b[34mOklahomans are hurting from Obamacare. Senate Republicans are committed to repealing and replacing the disastrous healthcare law. \u001b[0m\n",
      "\u001b[32m['Obamacare is causing problems for Oklahomans', 'The healthcare law needs to be repealed and replaced', 'Oklahoma residents are negatively impacted by the healthcare law', 'Republicans are commited to a better healthcare system', 'Obamacare is bad for America']\u001b[0m\n",
      "\u001b[31mObamacare is bad for America\u001b[0m\n",
      "\u001b[34m#Trumpcare would pull rug out from under critical access hospitals, like this one in Holyoke, CO, that help patients access lifesaving care.  \u001b[0m\n",
      "\u001b[32m['Critical access hospitals will be at risk under Trumpcare', 'Trumpcare will have a negative impact on access to healthcare', 'People rely on critical access hospitals for lifesaving care', 'The Holyoke, CO hospital is vital for providing medical attention', 'Trumpcare is bad for American healthcare']\u001b[0m\n",
      "\u001b[31mTrumpcare is bad for American healthcare\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n",
      "45 489\n",
      "Distance moved from 0.6546798944473267 -> 0.23371076583862305\n",
      "\u001b[34mOklahomans are hurting from Obamacare. Senate Republicans are committed to repealing and replacing the disastrous healthcare law. \u001b[0m\n",
      "\u001b[32m['Obamacare is causing problems for Oklahomans', 'The healthcare law needs to be repealed and replaced', 'Oklahoma residents are negatively impacted by the healthcare law', 'Republicans are commited to a better healthcare system', 'Obamacare is bad for America']\u001b[0m\n",
      "\u001b[31mRepublicans are commited to a better healthcare system\u001b[0m\n",
      "\u001b[34mGraham-Cassidy-Heller-Johnson is \"the most coherent of the proposals Republicans have looked at this year.\" \u001b[0m\n",
      "\u001b[32m['Graham-Cassidy-Heller-Johnson is the best Republican healthcare proposal', 'Healthcare reform is needed', 'Republicans have considered many healthcare proposals', 'Graham-Cassidy-Heller-Johnson is well-constructed']\u001b[0m\n",
      "\u001b[31mRepublicans have considered many healthcare proposals\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|█████████████████▉                                                                                                                                                                              | 46728/499500 [00:16<02:44, 2752.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 473\n",
      "Distance moved from 0.6497713327407837 -> 0.21559488773345947\n",
      "\u001b[34mWhat is Trump afraid of? According to news reports President Trump himself has acknowledged that the release of the Nunes memo was designed to disrupt Robert Mueller’s investigation. No political stunt should interfere with the special counsel’s work.\u001b[0m\n",
      "\u001b[32m[\"Trump fears Mueller's investigation\", 'The Nunes memo was released with the intent of hindering the investigation', \"The special counsel's investigation is important\", 'Political stunts should not be used to interfere with investigations', 'The Nunes memo was a political stunt']\u001b[0m\n",
      "\u001b[31mThe special counsel's investigation is important\u001b[0m\n",
      "\u001b[34mHours after Americans voted for an independent check on his administration, @realDonaldTrump fires the Attorney General and installs a partisan ally to oversee the Mueller probe. \n",
      "\n",
      "This isn’t a coincidence. We need accountability and to protect the Special Counsel’s investigation\u001b[0m\n",
      "\u001b[32m['Donald Trump has fired the Attorney General', \"Trump's actions may be an attack on the Mueller investigation\", 'The Mueller investigation should be protected', 'The firing of Jeff Sessions was political', \"Special Counsel's investigation deserves protection\"]\u001b[0m\n",
      "\u001b[31mSpecial Counsel's investigation deserves protection\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n",
      "47 484\n",
      "Distance moved from 0.661644458770752 -> 0.1752016544342041\n",
      "\u001b[34mWhat is Trump afraid of? According to news reports President Trump himself has acknowledged that the release of the Nunes memo was designed to disrupt Robert Mueller’s investigation. No political stunt should interfere with the special counsel’s work.\u001b[0m\n",
      "\u001b[32m[\"Trump fears Mueller's investigation\", 'The Nunes memo was released with the intent of hindering the investigation', \"The special counsel's investigation is important\", 'Political stunts should not be used to interfere with investigations', 'The Nunes memo was a political stunt']\u001b[0m\n",
      "\u001b[31mPolitical stunts should not be used to interfere with investigations\u001b[0m\n",
      "\u001b[34mFBI Deputy Director McCabe is a public servant, and @POTUS’ attacks on him undermine our democratic institutions. \n",
      "\n",
      "FBI investigations should be entirely free from political influence or intimidation. The independence of the agency is critical to the rule of law.\u001b[0m\n",
      "\u001b[32m['Donald Trump should not attack FBI officials', 'The FBI should be independent of the White House', 'Politics should not influence investigations', 'FBI Deputy Director McCabe is a public servant', 'Upholding the rule of law is crucial for democracy']\u001b[0m\n",
      "\u001b[31mPolitics should not influence investigations\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████████████████▎                                                                                                                                                                             | 47555/499500 [00:16<02:47, 2694.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 378\n",
      "Distance moved from 0.6953812837600708 -> 0.16763520240783691\n",
      "\u001b[34mIntroduced the Keep Families Together &amp; Enforce the Law Act. This bill would #KeepFamiliesTogether during legal proceedings, protect children, authorize 225 more immigration judges &amp; ensure the integrity of our immigration laws.\u001b[0m\n",
      "\u001b[32m['The Keep Families Together & Enforce the Law Act will protect immigrant families', 'Children deserve protection', 'More immigration judges are needed', 'Immigration laws must be upheld', 'The immigration system is in need of reform']\u001b[0m\n",
      "\u001b[31mThe immigration system is in need of reform\u001b[0m\n",
      "\u001b[34m.@RepJayapal visited a federal prison and met with asylum seekers who had been transferred from the border. What they told her is horrifying. We need to fight back against Trump's cruel immigration policy.  \u001b[0m\n",
      "\u001b[32m['Asylum seekers are being mistreated', 'A congresswoman visited a federal prison', \"The Trump administration's immigration policies are cruel\", 'Immigration policies need reform', 'Prison conditions in federal facilities may be poor']\u001b[0m\n",
      "\u001b[31mImmigration policies need reform\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n",
      "48 888\n",
      "Distance moved from 0.49630260467529297 -> 0.041860342025756836\n",
      "\u001b[34mIntroduced the Keep Families Together &amp; Enforce the Law Act. This bill would #KeepFamiliesTogether during legal proceedings, protect children, authorize 225 more immigration judges &amp; ensure the integrity of our immigration laws.\u001b[0m\n",
      "\u001b[32m['The Keep Families Together & Enforce the Law Act will protect immigrant families', 'Children deserve protection', 'More immigration judges are needed', 'Immigration laws must be upheld', 'The immigration system is in need of reform']\u001b[0m\n",
      "\u001b[31mThe immigration system is in need of reform\u001b[0m\n",
      "\u001b[34mCurrently govt must either release parents &amp; continue incentive for illegal entry with children or seperate families by detaining parents. Neither is good. Lets change the law to allow families to be held together at family facilities &amp; shorten detention with expedited hearings\u001b[0m\n",
      "\u001b[32m['The government is in a bind when dealing with families of illegal immigrants', 'The current system incentivizes illegal immigration', 'Separating families is inhumane', 'Families should be held together in facilities', 'Detention for illegal immigrants should be shortened with more expedited hearings', 'The immigration system needs reform']\u001b[0m\n",
      "\u001b[31mThe immigration system needs reform\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████████████████▊                                                                                                                                                                             | 48968/499500 [00:16<02:38, 2837.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 658\n",
      "Distance moved from 0.9463708996772766 -> 0.28416907787323\n",
      "\u001b[34mMore than 20 different government entities administer more than 160 different federal housing programs. I sent a letter asking for officials to identify duplication and overlap in federal housing assistance programs. \u001b[0m\n",
      "\u001b[32m['The federal government provides housing assistance through many different agencies', 'Housing programs may be unnecessarily duplicated', 'The government should reduce inefficiencies in federal housing programs', \"Taxpayers' money should be spent wisely\", 'A letter was sent to officials asking for a review of housing programs']\u001b[0m\n",
      "\u001b[31mTaxpayers' money should be spent wisely\u001b[0m\n",
      "\u001b[34mWe spent over $170k to build trails in national parks. Seems like not too bad until you read the next line that the parks were in Russia\u001b[0m\n",
      "\u001b[32m['Taxpayer money was used to build trails in Russian national parks', 'US funds should be used within the US', 'US money going to foreign countries can be problematic', 'The use of taxpayer funds should be closely scrutinized', 'Money should be invested in the US']\u001b[0m\n",
      "\u001b[31mThe use of taxpayer funds should be closely scrutinized\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████████████▍                                                                                                                                                                            | 50663/499500 [00:17<02:34, 2897.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 83\n",
      "Distance moved from 0.6601841449737549 -> 0.1399441957473755\n",
      "\u001b[34mNew Hampshire, there are four more days left to #GetCovered. The Affordable Care Act open enrollment period ends December 15. Go to  today to get started. \u001b[0m\n",
      "\u001b[32m['The open enrollment period for the Affordable Care Act is closing soon', 'New Hampshire residents have four days left to sign up', 'Healthcare is important for all Americans', 'Healthcare costs should be affordable']\u001b[0m\n",
      "\u001b[31mHealthcare is important for all Americans\u001b[0m\n",
      "\u001b[34m🚨 Our fight to protect health care for millions of families is not over.  \n",
      "\n",
      "Spread far and wide if useful. \u001b[0m\n",
      "\u001b[32m['A fight to protect healthcare has been undertaken', 'Millions of American families depend on the ACA for healthcare', 'Healthcare should be available for all Americans', 'We must keep fighting for healthcare']\u001b[0m\n",
      "\u001b[31mHealthcare should be available for all Americans\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n",
      "52 92\n",
      "Distance moved from 0.5998044013977051 -> 0.1719595193862915\n",
      "\u001b[34mNew Hampshire, there are four more days left to #GetCovered. The Affordable Care Act open enrollment period ends December 15. Go to  today to get started. \u001b[0m\n",
      "\u001b[32m['The open enrollment period for the Affordable Care Act is closing soon', 'New Hampshire residents have four days left to sign up', 'Healthcare is important for all Americans', 'Healthcare costs should be affordable']\u001b[0m\n",
      "\u001b[31mHealthcare costs should be affordable\u001b[0m\n",
      "\u001b[34mIt’s time to come together &amp; do what is best for the American people - make quality health care affordable for all Americans\u001b[0m\n",
      "\u001b[32m['Affordable healthcare should be available to all Americans', 'The wellbeing of the American people is important', 'A bipartisan solution is necessary to achieve affordable healthcare', 'All Americans should have access to quality healthcare']\u001b[0m\n",
      "\u001b[31mAffordable healthcare should be available to all Americans\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n",
      "52 93\n",
      "Distance moved from 0.6161491870880127 -> 0.20667314529418945\n",
      "\u001b[34mNew Hampshire, there are four more days left to #GetCovered. The Affordable Care Act open enrollment period ends December 15. Go to  today to get started. \u001b[0m\n",
      "\u001b[32m['The open enrollment period for the Affordable Care Act is closing soon', 'New Hampshire residents have four days left to sign up', 'Healthcare is important for all Americans', 'Healthcare costs should be affordable']\u001b[0m\n",
      "\u001b[31mHealthcare costs should be affordable\u001b[0m\n",
      "\u001b[34m(2/2) Health care reform should be focused on choice, not mandates. Yet, it is important that we protect people with pre-existing conditions, as we repeal and replace Obamacare.\u001b[0m\n",
      "\u001b[32m['Health care reform should promote individual choice', 'Obamacare should be replaced with a better system', 'People with pre-existing conditions should be protected', 'Health care should be affordable and accessible', 'Mandates in health care should be reduced or eliminated']\u001b[0m\n",
      "\u001b[31mHealth care should be affordable and accessible\u001b[0m\n",
      "**************\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# find pairs where distance is low(er) in decomposition space but high in comment space \n",
    "from nltk.tokenize import TweetTokenizer \n",
    "tt = TweetTokenizer() \n",
    "\n",
    "# change this value to control the number of examples displayed \n",
    "num_display_examples = 25\n",
    "counter = 0 \n",
    "\n",
    "for pair in tqdm(pairs): \n",
    "    if counter > num_display_examples: \n",
    "        break \n",
    "    \n",
    "    index1, index2 = pair\n",
    "    doc_distance = float(doc_distances[index1, index2])\n",
    "    decomp_distance = decomp_dists[index1, index2] \n",
    "    #print(doc_distance, decomp_distance, doc_distance - decomp_distance) \n",
    "    \n",
    "    # find docs of similar length\n",
    "    if not abs(len(tt.tokenize(tweet_texts[index1])) - len(tt.tokenize(tweet_texts[index2]))) < 10: \n",
    "        continue \n",
    "\n",
    "    # find docs where the shift is more than 0.5 and distance over decomposition is low \n",
    "    # change these values accoring \n",
    "    if doc_distance - decomp_distance > 0.4 and decomp_distance < 0.3: \n",
    "        print(index1, index2)\n",
    "        print(f\"Distance moved from {doc_distance} -> {decomp_distance}\")\n",
    "        a = distance_func(decomp_embeddings[index1], decomp_embeddings[index2])\n",
    "        \n",
    "        print(blue(tweet_texts[index1]))\n",
    "        print(green(decompositions[index1]))\n",
    "        print(red(decompositions[index1][a[0]]))\n",
    "    \n",
    "        print(blue(tweet_texts[index2]))\n",
    "        print(green(decompositions[index2]))\n",
    "        print(red(decompositions[index2][a[1]]))\n",
    "        print(\"**************\")\n",
    "        print(\"\\n\\n\")\n",
    "        counter += 1\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:decompositions] *",
   "language": "python",
   "name": "conda-env-decompositions-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
